{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75325ea9-835e-4db4-8070-9535edf8c745",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/606 [..............................] - ETA: 1:48 - loss: 1.7942 - accuracy: 0.0914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 09:47:01.033028: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 2s 3ms/step - loss: 0.4289 - accuracy: 0.8619\n",
      "Epoch 2/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0470 - accuracy: 0.9942\n",
      "Epoch 3/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0284 - accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0172 - accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0145 - accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "606/606 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "606/606 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0105 - accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "606/606 [==============================] - 2s 3ms/step - loss: 0.0095 - accuracy: 0.9979\n",
      "CPU Usage: 1.2%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "df1 = pd.read_csv('sms-call-internet-mi-2013-11-04.csv')\n",
    "df2 = pd.read_csv('sms-call-internet-mi-2013-11-05.csv')\n",
    "df3 = pd.read_csv('sms-call-internet-mi-2013-11-06.csv')\n",
    "df4 = pd.read_csv('sms-call-internet-mi-2013-11-07.csv')\n",
    "df5 = pd.read_csv('sms-call-internet-mi-2013-11-08.csv')\n",
    "df6 = pd.read_csv('sms-call-internet-mi-2013-11-09.csv')\n",
    "df7 = pd.read_csv('sms-call-internet-mi-2013-11-10.csv')\n",
    "\n",
    "dfs = [df1, df2, df3, df4, df5, df6, df7]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.drop(columns=['datetime'])\n",
    "df.dropna(inplace=True)\n",
    "cols = [\"smsin\", \"smsout\", \"callin\", \"callout\", \"internet\"]\n",
    "df[\"total_activity\"] = df[cols].sum(axis = 1)\n",
    "\n",
    "def assign_activity(total_activity):\n",
    "    if total_activity <= 20:\n",
    "        return 1\n",
    "    elif total_activity <= 40:\n",
    "        return 2\n",
    "    elif total_activity <= 60:\n",
    "        return 3\n",
    "    elif total_activity <= 80:\n",
    "        return 4\n",
    "    elif total_activity <= 100:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df['activity_number'] = df['total_activity'].apply(assign_activity)\n",
    "df['activity_number'] = df['activity_number'] - 1\n",
    "\n",
    "\n",
    "\n",
    "X = df[[\"smsin\", \"smsout\", \"callin\", \"callout\", \"internet\"]]\n",
    "y = df[[\"activity_number\"]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
